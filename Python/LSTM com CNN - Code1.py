# -*- coding: utf-8 -*-
"""TeseFinalDoutorado(LSTM e CNN).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bKYmrgxobekcfNZMGkeX69pk7KGOzUp2
"""

pip install tensorflow pandas matplotlib

pip install tqdm

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import random
from datetime import datetime
from PIL import Image, UnidentifiedImageError  # Importação correta da biblioteca de imagens
from tqdm import tqdm

# Seed para reprodutibilidade
seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)
random.seed(seed)

# Carregando dados do CSV
data = pd.read_csv('/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/Fazenda Sao Benedito/LSTM com CNN/Fazenda_DadosConsolidados_2022_2024_CSV.csv', delimiter=';')  # Ajuste o delimitador conforme o arquivo
data['Data Leitura'] = pd.to_datetime(data['Data Leitura'], format='%d/%m/%Y')

# Remover colunas não necessárias
data = data.drop(columns=['Bacia Estudo'])

# Selecionar colunas para o modelo
features = ['Precipitacao', 'Pressao Atmosferica Estacao', 'Pressao Atmosferica Max', 'Pressao Atmosferica Min',
            'Radiacao Global', 'Temperatura Bulbo', 'Temperatura Ponto Orvalho', 'Temperatura Max', 'Temperatura Min',
            'Temperatura Orvalho Max', 'Temperatura Orvalho Min', 'Umidade Max Hora Ant', 'Umidade Min Hora Ant',
            'Umidade Relativa Ar', 'Vento Direcao Horaria', 'Vento Rajada', 'Vento Velocidade Horaria']
target = 'Vazao Observada'

# Dividir dados em treino e teste, mas mantendo a coluna de Data Leitura
X_train, X_test, y_train, y_test = train_test_split(data[features + ['Data Leitura']], data[target], test_size=0.2, random_state=seed)

# Definir train_dates e test_dates a partir da coluna 'Data Leitura'
train_dates = X_train['Data Leitura'].dt.strftime('%d-%m-%Y').tolist()  # Extrai as datas formatadas de X_train
test_dates = X_test['Data Leitura'].dt.strftime('%d-%m-%Y').tolist()    # Extrai as datas formatadas de X_test

# Remover a coluna 'Data Leitura' de X_train e X_test, pois não será usada como entrada do modelo
#X_train = X_train.drop(columns=['Data Leitura'])
#X_test = X_test.drop(columns=['Data Leitura'])

def load_images_for_date(date):
    # Carrega imagens correspondentes a cada horário
    image_paths = [
         f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_10.jpeg",
         f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_12.jpeg",
         f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_14.jpeg",
         f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_16.jpeg"
    ]
    images = []
    for path in image_paths:
        try:
            with Image.open(path) as img:
                images.append(np.array(img.resize((256, 256))))  # Ajusta a imagem para 256x256
        except (FileNotFoundError, UnidentifiedImageError) as e:
            print(f"Aviso: Não foi possível carregar a imagem {path}. Erro: {e}")
            continue
    # Confere se todas as 4 imagens foram carregadas
    if len(images) != 4:
        print(f"Erro: Número de imagens para {date} não é 4.")
    return np.array(images)

# Modelo CNN para processar imagens
cnn_model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(256, 256, 3)),
    MaxPooling2D((2,2)),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D((2,2)),
    Flatten(),
    Dense(64, activation='relu')
])

# Modelo LSTM para dados tabulares e combinação com CNN
def create_combined_model():
    cnn_input = tf.keras.Input(shape=(4, 256, 256, 3))  # Para 4 imagens por dia
    cnn_features = tf.keras.layers.TimeDistributed(cnn_model)(cnn_input)
    cnn_features = LSTM(64)(cnn_features)

    # Entrada para dados tabulares
    lstm_input = tf.keras.Input(shape=(len(features),))
    dense_features = Dense(64, activation='relu')(lstm_input)

    # Combinar CNN e LSTM
    combined = tf.keras.layers.concatenate([cnn_features, dense_features])
    output = Dense(1, activation='linear')(combined)

    model = tf.keras.Model(inputs=[cnn_input, lstm_input], outputs=output)
    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])
    return model

model = create_combined_model()

"""3. Treinamento e Avaliação python

"""

# Preparação dos dados de imagem e tabulares
def prepare_data(dataframe, target_column, all_dates):
    X_tabular, X_images, y = [], [], []
    for i, date in enumerate(tqdm(all_dates, desc="Preparando dados")):
        img_data = load_images_for_date(date)

        # Verifique se foram carregadas exatamente 4 imagens
        if img_data.shape[0] == 4:
            X_images.append(img_data)

            # Garantir que os dados tabulares sejam apenas numéricos
            tabular_data = dataframe.iloc[i][features].values  # Apenas as colunas selecionadas
            X_tabular.append(tabular_data)

            y.append(target_column.iloc[i])  # Adiciona a vazão observada (target)
        else:
            print(f"Erro: Número de imagens para {date} não é 4.")

    X_tabular = np.array(X_tabular)
    print("Shape de X_tabular:", X_tabular.shape)  # Verifique a forma aqui
    return [np.array(X_images), X_tabular], np.array(y)

# Preparar os dados, passando as variáveis corretamente
X_train_data, y_train_data = prepare_data(X_train, y_train, train_dates)
X_test_data, y_test_data = prepare_data(X_test, y_test, test_dates)

# Filtrar apenas as colunas numéricas
X_train_data[1] = pd.DataFrame(X_train_data[1]).select_dtypes(include=[np.number]).values
X_test_data[1] = pd.DataFrame(X_test_data[1]).select_dtypes(include=[np.number]).values

# Agora, converta os dados tabulares para o tipo float32
X_train_data[1] = X_train_data[1].astype(np.float32)  # Dados tabulares
y_train_data = y_train_data.astype(np.float32)  # Alvo

X_test_data[1] = X_test_data[1].astype(np.float32)  # Dados tabulares
y_test_data = y_test_data.astype(np.float32)  # Alvo

# Treinamento
history = model.fit(X_train_data, y_train_data, epochs=1, validation_data=(X_test_data, y_test_data))

"""4. Geração de Gráficos e Relatório"""

# Previsão e avaliação
y_pred = model.predict(X_test_data)

# Cálculo de métricas
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")

# Preparar dados para o gráfico
dates = pd.to_datetime(X_test['Data Leitura']).dt.strftime('%d-%m-%Y')  # Convertendo para o formato de string desejado
y_test_values = y_test.values
y_pred_values = y_pred.flatten()

# Gráfico de comparação
plt.figure(figsize=(12, 6))
plt.plot(dates, y_test_values, label="Observado", marker='o', linestyle='-')
plt.plot(dates, y_pred_values, label="Calculado", marker='x', linestyle='--')
plt.xlabel("Data da Leitura")
plt.ylabel("Vazão")
plt.title("Comparação entre Vazão Observada e Calculada")
plt.xticks(rotation=45)  # Rotaciona as datas no eixo X para melhor visualização
plt.legend()
plt.tight_layout()  # Ajusta o layout para evitar cortes no gráfico
plt.show()

# Relatório CSV
results = pd.DataFrame({
    'Data_Leitura': X_test['Data Leitura'].values,  # Acessando diretamente do DataFrame
    'Valor_Calculado': y_pred.flatten(),
    'Valor_Observado': y_test.values,
    'Erro': y_test.values - y_pred.flatten()
})

results.to_csv(r'C:/Temp/relatorio_previsao.csv', index=False)