# -*- coding: utf-8 -*-
"""Doutorado-IbitingaInvernada-LSTM_e_VisionTransformer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10v5ctu7pf9I12zJzKhDEJEHQz_NgE26Z
"""

# Implementação de LSTM concatenada ao modelo Vision Transformer (Ibitinga - Gavião Peixoto) - Tese de doutorado

# Instalação de dependências
# Instale as dependências principais
!pip install tensorflow matplotlib tqdm tensorflow-addons==0.23.0 vit-keras==0.1.2

# Instale o typeguard explicitamente na versão mínima exigida ou superior
!pip install typeguard>=4.0.1

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, LSTM, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import random
from datetime import datetime
from PIL import Image, UnidentifiedImageError
from tqdm import tqdm
from google.colab import drive
import glob  # Adicionado aqui
from tensorflow.keras.layers import Layer

# Montar Google Drive
drive.mount('/content/drive')

# # Configuração de checkpoints
# checkpoint_path = "/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/CheckPoint_epoch_*.weights.h5"
# checkpoints = glob.glob(checkpoint_path)
# if checkpoints:
#     latest_checkpoint = max(checkpoints, key=os.path.getctime)
#     print(f"Último checkpoint encontrado: {latest_checkpoint}")
#     try:
#         epoch_str = latest_checkpoint.split("_epoch_")[1].split(".weights.h5")[0]
#         initial_epoch = int(epoch_str)
#         print(f"Última época carregada: {initial_epoch}")
#     except (IndexError, ValueError) as e:
#         print(f"Erro ao extrair o número da época: {e}. Definindo initial_epoch como 0.")
#         initial_epoch = 0
# else:
#     initial_epoch = 0

# checkpoint_path_callback = "/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/CheckPoint_epoch_{epoch:02d}.weights.h5"
# checkpoint_callback = ModelCheckpoint(
#     filepath=checkpoint_path_callback,
#     save_weights_only=True,
#     save_best_only=False,
#     monitor='val_loss',
#     mode='min',
#     verbose=1
# )

# Seed para reprodutibilidade
seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)
random.seed(seed)

# Carregando dados do CSV
data = pd.read_csv('/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/IBITINGA INVERNADA/LSTM com ViT/IBITINGA INVERNADA - Dados para processar Rede-CSV.csv', delimiter=';')
data['Data Leitura'] = pd.to_datetime(data['Data Leitura'], format='%d/%m/%Y')

# Remover colunas não necessárias
data = data.drop(columns=['Bacia Estudo'])

# Selecionar colunas para o modelo
features = ['Precipitacao', 'Pressao Atmosferica Estacao', 'Pressao Atmosferica Max', 'Pressao Atmosferica Min',
            'Radiacao Global', 'Temperatura Bulbo', 'Temperatura Ponto Orvalho', 'Temperatura Max', 'Temperatura Min',
            'Temperatura Orvalho Max', 'Temperatura Orvalho Min', 'Umidade Max Hora Ant', 'Umidade Min Hora Ant',
            'Umidade Relativa Ar', 'Vento Direcao Horaria', 'Vento Rajada', 'Vento Velocidade Horaria']
target = 'Vazao Observada'

# Dividir dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(data[features + ['Data Leitura']], data[target], test_size=0.2, random_state=seed)

# Definir train_dates e test_dates
train_dates = X_train['Data Leitura'].dt.strftime('%d-%m-%Y').tolist()
test_dates = X_test['Data Leitura'].dt.strftime('%d-%m-%Y').tolist()

# Remover a coluna 'Data Leitura' de X_train e X_test
X_train = X_train.drop(columns=['Data Leitura'])
X_test = X_test.drop(columns=['Data Leitura'])

# Função para carregar imagens e criar mosaico
def load_and_create_mosaic(date):
    image_paths = [
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_10.jpeg",
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_12.jpeg",
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_14.jpeg",
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_16.jpeg"
    ]
    images = []
    for path in image_paths:
        try:
            with Image.open(path) as img:
                images.append(np.array(img.resize((128, 128))))  # Redimensiona para 128x128
        except (FileNotFoundError, UnidentifiedImageError) as e:
            print(f"Aviso: Não foi possível carregar a imagem {path}. Erro: {e}")
            return None
    if len(images) != 4:
        print(f"Erro: Número de imagens para {date} não é 4.")
        return None

    # Criar mosaico 2x2 (256x256)
    mosaic = np.zeros((256, 256, 3), dtype=np.uint8)
    mosaic[0:128, 0:128] = images[0]  # 10h
    mosaic[0:128, 128:256] = images[1]  # 12h
    mosaic[128:256, 0:128] = images[2]  # 14h
    mosaic[128:256, 128:256] = images[3]  # 16h
    return mosaic

# Camada personalizada para extrair patches
class PatchExtractor(Layer):
    def __init__(self, patch_size):
        super(PatchExtractor, self).__init__()
        self.patch_size = patch_size

    def call(self, images):
        batch_size = tf.shape(images)[0]
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.patch_size, self.patch_size, 1],
            strides=[1, self.patch_size, self.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding='VALID'
        )
        patch_dims = patches.shape[-1]
        patches = tf.reshape(patches, [batch_size, -1, patch_dims])
        return patches

# Implementação simplificada do Vision Transformer (ViT)
def create_vit_model(input_shape=(256, 256, 3), patch_size=16, num_patches=256, projection_dim=64, num_heads=4, transformer_layers=4):
    inputs = Input(shape=input_shape)

    # Extração de patches
    patches = PatchExtractor(patch_size)(inputs)

    # Projeção dos patches
    patch_embeddings = Dense(projection_dim)(patches)

    # Adicionar positional embeddings
    positions = tf.range(start=0, limit=num_patches, delta=1)
    position_embeddings = tf.keras.layers.Embedding(input_dim=num_patches, output_dim=projection_dim)(positions)
    embeddings = patch_embeddings + position_embeddings

    # Camadas Transformer
    for _ in range(transformer_layers):
        attn_output = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim)(embeddings, embeddings)
        embeddings = tf.keras.layers.Add()([embeddings, attn_output])
        embeddings = tf.keras.layers.LayerNormalization(epsilon=1e-6)(embeddings)

        ff_output = Dense(projection_dim * 2, activation='gelu')(embeddings)
        ff_output = Dense(projection_dim)(ff_output)
        embeddings = tf.keras.layers.Add()([embeddings, ff_output])
        embeddings = tf.keras.layers.LayerNormalization(epsilon=1e-6)(embeddings)

    # Pooling global e saída
    vit_output = tf.keras.layers.GlobalAveragePooling1D()(embeddings)
    vit_output = Dense(64, activation='relu')(vit_output)

    return Model(inputs=inputs, outputs=vit_output)

# Modelo combinado LSTM + ViT
def create_combined_model():
    # learning_rate = 0.001
    # MyOptimizer = Adam(learning_rate=learning_rate)

    # vit_input = Input(shape=(256, 256, 3))
    # vit_model = create_vit_model()
    # vit_features = vit_model(vit_input)

    # lstm_input = Input(shape=(len(features),))
    # dense_features = Dense(64, activation='relu')(lstm_input)

    # combined = concatenate([vit_features, dense_features])
    # output = Dense(1, activation='linear')(combined)

    # model = Model(inputs=[vit_input, lstm_input], outputs=output)
    # model.compile(optimizer=MyOptimizer, loss='mean_squared_error', metrics=['mae'])
    # return model
    learning_rate = 0.001
    MyOptimizer = Adam(learning_rate=learning_rate)

    vit_input = Input(shape=(256, 256, 3))
    vit_model = create_vit_model()
    vit_features = vit_model(vit_input)

    lstm_input = Input(shape=(len(features),))
    dense_features = Dense(64, activation='relu')(lstm_input)

    combined = concatenate([vit_features, dense_features])
    output = Dense(1, activation='linear')(combined)

    model = Model(inputs=[vit_input, lstm_input], outputs=output)
    model.compile(optimizer=MyOptimizer, loss='mean_squared_error', metrics=['mae'])
    return model

model = create_combined_model()

# Preparação dos dados
def prepare_data(dataframe, target_column, all_dates):
    X_tabular, X_images, y = [], [], []
    for i, date in enumerate(tqdm(all_dates, desc="Preparando dados")):
        mosaic = load_and_create_mosaic(date)
        if mosaic is not None:
            X_images.append(mosaic)
            X_tabular.append(dataframe.iloc[i].values)
            y.append(target_column.iloc[i])
        else:
            print(f"Erro: Mosaico não criado para {date}.")

    return [np.array(X_images), np.array(X_tabular)], np.array(y)

# Preparar os dados
X_train_data, y_train_data = prepare_data(X_train, y_train, train_dates)
X_test_data, y_test_data = prepare_data(X_test, y_test, test_dates)

# Normalizar imagens (0 a 1)
X_train_data[0] = X_train_data[0] / 255.0
X_test_data[0] = X_test_data[0] / 255.0

# Garantir tipo numérico
X_train_data[1] = X_train_data[1].astype(np.float32)
X_test_data[1] = X_test_data[1].astype(np.float32)
y_train_data = y_train_data.astype(np.float32)
y_test_data = y_test_data.astype(np.float32)

# Treinamento
inicio_processo = datetime.now()
history = model.fit(
    X_train_data,
    y_train_data,
    epochs=100,
    validation_data=(X_test_data, y_test_data),
    batch_size=64
    # initial_epoch=initial_epoch,
    # callbacks=[checkpoint_callback]
)
fim_processo = datetime.now()

Tempo_execucao_minutos = (fim_processo - inicio_processo).total_seconds() / 60
print(f"Tempo de execução: {Tempo_execucao_minutos:.2f} minutos.")

# Previsão e avaliação
y_pred = model.predict(X_test_data)

# Cálculo de métricas
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")

# Gráfico de comparação
plt.figure(figsize=(10, 5))
plt.plot(y_test, label="Observado")
plt.plot(y_pred, label="Calculado")
plt.xlabel("Dia")
plt.ylabel("Vazão")
plt.legend()
plt.show()

# Filtrar as datas correspondentes ao conjunto de teste
test_indices = data.index[-len(y_test):]
data_test = data.loc[test_indices, 'Data Leitura']

# Criação do DataFrame para o relatório
results = pd.DataFrame({
    'Data_Leitura': data_test,
    'Valor_Calculado': y_pred.flatten(),
    'Valor_Observado': y_test.values,
    'Erro': y_test.values - y_pred.flatten()
})

# Nome do arquivo com data atual
hoje = datetime.now().strftime('%d_%m_%Y')
nome_arquivo = f"ResultadosIbitingaInvernada_LSTM_ViT_{hoje}.csv"
output_path = f'/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/IBITINGA INVERNADA/LSTM com ViT/{nome_arquivo}'

# Criar diretório se não existir
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Salvar o arquivo CSV
results.to_csv(output_path, index=False, sep=';')
print(f"Arquivo salvo em: {output_path}")