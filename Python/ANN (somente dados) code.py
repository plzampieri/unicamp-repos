# -*- coding: utf-8 -*-
"""IbitingaGaviaoPeixoto-TeseFinalDoutorado(ANN apenas).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1whOC0HARXp5ziprkcct_VluBkdKehhzM
"""

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler

# Seed para reprodutibilidade
seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)

from google.colab import drive
drive.mount('/content/drive')

sCaminho = "/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/"
sUsina = "IBITINGA GAVIAO PEIXOTO/"
sRede = "ANN/"
sArquivo = "IBITINGA GAVIAO PEIXOTO - Dados para processar rede-CSV.csv"
FullPath = sCaminho + sUsina + sRede + sArquivo

# # Obter a data atual no formato DD_MM_YYYY
hoje = datetime.now().strftime('%d_%m_%Y')
# Definir o nome do arquivo
sNome_arquivo_exportado = f"ResultadosIbitingaGaviaoPeixoto_ANN_Apenas_{hoje}.csv"

# Carregando dados do CSV
#data = pd.read_csv('/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/Fazenda Sao Benedito/ANN/Fazenda_DadosConsolidados_2022_2024_CSV.csv', delimiter=';')  # Ajuste o delimitador conforme o arquivo
data = pd.read_csv(FullPath, delimiter=';')  # Ajuste o delimitador conforme o arquivo
data['Data Leitura'] = pd.to_datetime(data['Data Leitura'], format='%d/%m/%Y')

# Remover colunas não necessárias
data = data.drop(columns=['Bacia Estudo'])

# Selecionar colunas para o modelo
features = ['Precipitacao', 'Pressao Atmosferica Estacao', 'Pressao Atmosferica Max', 'Pressao Atmosferica Min',
            'Radiacao Global', 'Temperatura Bulbo', 'Temperatura Ponto Orvalho', 'Temperatura Max', 'Temperatura Min',
            'Temperatura Orvalho Max', 'Temperatura Orvalho Min', 'Umidade Max Hora Ant', 'Umidade Min Hora Ant',
            'Umidade Relativa Ar', 'Vento Direcao Horaria', 'Vento Rajada', 'Vento Velocidade Horaria']
target = 'Vazao Observada'

# Dividir dados em treino e teste
X = data[features]
y = data[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)

# Guardar os índices de X_test para acessar as datas posteriormente
test_indices = X_test.index

scaler = MinMaxScaler()
X_normalized = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=seed)

#mudança em 16/01/2025
model = Sequential([
    Dense(512, activation='relu', input_shape=(len(features),)),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(32, activation='relu'),
    Dense(1, activation='linear')
])

# Trocado em 16/01/2025 para ver se melhora o modelo.
learning_rate = 0.001
optimizer = Adam(learning_rate=learning_rate)
model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae', 'mse'])

# Treinar o modelo
history = model.fit(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=800,
    batch_size=64
)
fim_processo = datetime.now()

# Tempo_execucao_minutos = (fim_processo - inicio_processo).total_seconds() /60
# print(f"tempo de execução: {Tempo_execucao_minutos:.2f} minutos.")

# Previsão
y_pred = model.predict(X_test)

# Cálculo de métricas
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)  # Calculando o RMSE a partir do MSE

print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")
print(f"Root Mean Squared Error (RMSE): {rmse}")

# Salvar os resultados
results = pd.DataFrame({
   'Data Leitura': data.loc[test_indices, 'Data Leitura'].values,  # Usar os índices originais
   #'Data Leitura': data.loc[X_test.index, 'Data Leitura'].values,  # Recuperar as datas corretas
    #'Data Leitura': X_test.index,  # Presume-se que o índice de X_test contenha as datas
    'Valor_Observado': y_test.values,
    'Valor_Calculado': y_pred.flatten(),
    'Erro': y_test.values - y_pred.flatten()
})

# Trocar o ponto decimal por vírgula nas colunas
results['Valor_Observado'] = results['Valor_Observado'].astype(str).str.replace('.', ',', regex=False)
results['Valor_Calculado'] = results['Valor_Calculado'].astype(str).str.replace('.', ',', regex=False)
results['Erro'] = results['Erro'].astype(str).str.replace('.', ',', regex=False)
results['Data Leitura'] = results['Data Leitura'].dt.strftime('%d/%m/%Y')

# Caminho completo no Google Drive
#output_path = f'/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/Fazenda Sao Benedito/ANN/{nome_arquivo}'
output_path = sCaminho + sUsina + sRede + sNome_arquivo_exportado

# Certifique-se de que a pasta existe antes de salvar
import os
os.makedirs(os.path.dirname(output_path), exist_ok=True)

# Salve o arquivo CSV no caminho especificado
results.to_csv(output_path, index=False, sep=';')

print(f"Arquivo salvo em: {output_path}")

