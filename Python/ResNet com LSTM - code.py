# -*- coding: utf-8 -*-
"""Doutorado_ResNet_e_LSTM_GaviaoPeixoto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/140kpikqjzv3FO0xDxq-o0lkCGvtZ83Lz
"""

#Doutorado-FazendaSaoBenedito-ResNet.ipynb"""

# Instalação de dependências
!pip install tensorflow matplotlib tqdm

import os
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, concatenate
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.applications import ResNet50
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
import random
from datetime import datetime
from PIL import Image, UnidentifiedImageError
from tqdm import tqdm
from google.colab import drive
import glob

# Montar Google Drive
drive.mount('/content/drive')

# Seed para reprodutibilidade
seed = 42
tf.random.set_seed(seed)
np.random.seed(seed)
random.seed(seed)

# Carregando dados do CSV
data = pd.read_csv('/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/IBITINGA GAVIAO PEIXOTO/LSTM com ResNet50/IBITINGA GAVIAO PEIXOTO - Dados para processar rede-CSV.csv', delimiter=';')
data['Data Leitura'] = pd.to_datetime(data['Data Leitura'], format='%d/%m/%Y')
data = data.drop(columns=['Bacia Estudo'])

features = ['Precipitacao', 'Pressao Atmosferica Estacao', 'Pressao Atmosferica Max', 'Pressao Atmosferica Min',
            'Radiacao Global', 'Temperatura Bulbo', 'Temperatura Ponto Orvalho', 'Temperatura Max', 'Temperatura Min',
            'Temperatura Orvalho Max', 'Temperatura Orvalho Min', 'Umidade Max Hora Ant', 'Umidade Min Hora Ant',
            'Umidade Relativa Ar', 'Vento Direcao Horaria', 'Vento Rajada', 'Vento Velocidade Horaria']
target = 'Vazao Observada'

# Dividir dados
X_train, X_test, y_train, y_test = train_test_split(data[features + ['Data Leitura']], data[target], test_size=0.2, random_state=seed)
train_dates = X_train['Data Leitura'].dt.strftime('%d-%m-%Y').tolist()
test_dates = X_test['Data Leitura'].dt.strftime('%d-%m-%Y').tolist()
X_train = X_train.drop(columns=['Data Leitura'])
X_test = X_test.drop(columns=['Data Leitura'])

# Função para carregar mosaicos
def load_and_create_mosaic(date):
    image_paths = [
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_10.jpeg",
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_12.jpeg",
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_14.jpeg",
        f"/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/GOES_Script e Imagens/IMG_2022_2023_2024 - 256 pixels/{date}_16.jpeg"
    ]
    images = []
    for path in image_paths:
        try:
            with Image.open(path) as img:
                images.append(np.array(img.resize((128, 128))))
        except (FileNotFoundError, UnidentifiedImageError) as e:
            print(f"Aviso: Não foi possível carregar a imagem {path}. Erro: {e}")
            return None
    if len(images) != 4:
        return None
    mosaic = np.zeros((256, 256, 3), dtype=np.uint8)
    mosaic[0:128, 0:128] = images[0]
    mosaic[0:128, 128:256] = images[1]
    mosaic[128:256, 0:128] = images[2]
    mosaic[128:256, 128:256] = images[3]
    return mosaic

# Modelo ResNet50
def create_resnet_model(input_shape=(256, 256, 3)):
    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')
    base_model.trainable = False  # Congelar camadas pré-treinadas
    inputs = Input(shape=input_shape)
    x = base_model(inputs)
    x = Dense(64, activation='relu')(x)
    return Model(inputs=inputs, outputs=x)

# Modelo combinado
def create_combined_model():
    learning_rate = 0.001
    optimizer = Adam(learning_rate=learning_rate)

    resnet_input = Input(shape=(256, 256, 3))
    resnet_model = create_resnet_model()
    resnet_features = resnet_model(resnet_input)

    tabular_input = Input(shape=(len(features),))
    dense_features = Dense(64, activation='relu')(tabular_input)

    combined = concatenate([resnet_features, dense_features])
    output = Dense(1, activation='linear')(combined)

    model = Model(inputs=[resnet_input, tabular_input], outputs=output)
    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])
    return model

model = create_combined_model()

# Preparação dos dados
def prepare_data(dataframe, target_column, all_dates):
    X_tabular, X_images, y = [], [], []
    for i, date in enumerate(tqdm(all_dates, desc="Preparando dados")):
        mosaic = load_and_create_mosaic(date)
        if mosaic is not None:
            X_images.append(mosaic)
            X_tabular.append(dataframe.iloc[i].values)
            y.append(target_column.iloc[i])
        else:
            print(f"Erro: Mosaico não criado para {date}.")
    return [np.array(X_images), np.array(X_tabular)], np.array(y)

X_train_data, y_train_data = prepare_data(X_train, y_train, train_dates)
X_test_data, y_test_data = prepare_data(X_test, y_test, test_dates)

X_train_data[0] = X_train_data[0] / 255.0
X_test_data[0] = X_test_data[0] / 255.0
X_train_data[1] = X_train_data[1].astype(np.float32)
X_test_data[1] = X_test_data[1].astype(np.float32)
y_train_data = y_train_data.astype(np.float32)
y_test_data = y_test_data.astype(np.float32)

# Treinamento
inicio_processo = datetime.now()
history = model.fit(
    X_train_data, y_train_data,
    epochs=100,
    validation_data=(X_test_data, y_test_data),
    batch_size=64
)
fim_processo = datetime.now()
print(f"Tempo de execução: {(fim_processo - inicio_processo).total_seconds() / 60:.2f} minutos.")

# Previsão e avaliação
y_pred = model.predict(X_test_data)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Absolute Error: {mae}")
print(f"Mean Squared Error: {mse}")

# Gráfico
plt.figure(figsize=(10, 5))
plt.plot(y_test, label="Observado")
plt.plot(y_pred, label="Calculado")
plt.xlabel("Dia")
plt.ylabel("Vazão")
plt.legend()
plt.show()

# Salvar resultados
test_indices = data.index[-len(y_test):]
data_test = data.loc[test_indices, 'Data Leitura']
results = pd.DataFrame({
    'Data_Leitura': data_test,
    'Valor_Calculado': y_pred.flatten(),
    'Valor_Observado': y_test.values,
    'Erro': y_test.values - y_pred.flatten()
})

hoje = datetime.now().strftime('%d_%m_%Y')
nome_arquivo = f"ResultadosGaviaoPeixoto_LSTM_ResNet50_{hoje}.csv"
output_path = f'/content/drive/MyDrive/Unicamp/Doutorado/TeseFinal_Dados/IBITINGA GAVIAO PEIXOTO/LSTM com ResNet50/{nome_arquivo}'
os.makedirs(os.path.dirname(output_path), exist_ok=True)
results.to_csv(output_path, index=False, sep=';')
print(f"Arquivo salvo em: {output_path}")

